{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646 646 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserTags</th>\n",
       "      <th>TimeStamps</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Canadian Press Politics\\n@CdnPressPoli</td>\n",
       "      <td>2024-01-11T14:46:47.000Z</td>\n",
       "      <td>Canada's federal government was warned two yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Canadian Press Politics\\n@CdnPressPoli</td>\n",
       "      <td>2024-01-11T14:46:47.000Z</td>\n",
       "      <td>MPs set to debate Ukraine trade deal, as Liber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Canadian Press Politics\\n@CdnPressPoli</td>\n",
       "      <td>2024-01-11T14:46:47.000Z</td>\n",
       "      <td>Ottawa locals to testify about 'Freedom Convoy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Canadian Press Politics\\n@CdnPressPoli</td>\n",
       "      <td>2024-01-11T14:46:47.000Z</td>\n",
       "      <td>India claims students at risk after envoy insi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Canadian Press Politics\\n@CdnPressPoli</td>\n",
       "      <td>2024-01-11T14:46:47.000Z</td>\n",
       "      <td>CSIS is leaning on Soviet imagery to help prim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     UserTags                TimeStamps  \\\n",
       "0  The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
       "1  The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
       "2  The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
       "3  The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
       "4  The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
       "\n",
       "                                              Tweets  \n",
       "0  Canada's federal government was warned two yea...  \n",
       "1  MPs set to debate Ukraine trade deal, as Liber...  \n",
       "2  Ottawa locals to testify about 'Freedom Convoy...  \n",
       "3  India claims students at risk after envoy insi...  \n",
       "4  CSIS is leaning on Soviet imagery to help prim...  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep\n",
    "\n",
    "PATH = \"C:\\Program Files\\drivers\\chromedriver_103.exe\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://twitter.com/login\")\n",
    "\n",
    "subject = \"The Canadian Press politics\"\n",
    "\n",
    "# Setup the log in\n",
    "sleep(3)\n",
    "username = driver.find_element(By.XPATH,\"//input[@name='text']\")\n",
    "username.send_keys(\"realmsvers\")  #\"ishaantk119\" \"kkworld9999\" \"realmsvers\"\n",
    "next_button = driver.find_element(By.XPATH,\"//span[contains(text(),'Next')]\")\n",
    "next_button.click()\n",
    "\n",
    "sleep(3)\n",
    "password = driver.find_element(By.XPATH,\"//input[@name='password']\")\n",
    "password.send_keys('carolvers93') #'kritijoshi@16feb' 'carolvers93'\n",
    "log_in = driver.find_element(By.XPATH,\"//span[contains(text(),'Log in')]\")\n",
    "log_in.click()\n",
    "\n",
    "# Search item and fetch it\n",
    "sleep(3)\n",
    "search_box = driver.find_element(By.XPATH,'//input[@data-testid=\"SearchBox_Search_Input\"]')\n",
    "search_box.send_keys(subject)\n",
    "search_box.send_keys(Keys.ENTER)\n",
    "\n",
    "sleep(3)\n",
    "people = driver.find_element(By.XPATH,\"//span[contains(text(),'People')]\")\n",
    "people.click()\n",
    "\n",
    "sleep(3)\n",
    "profile = driver.find_element(By.XPATH,'//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div[1]/div/div[3]/section/div/div/div[1]/div/div/button/div/div[2]/div/div[1]/div/div[1]/a/div/div[1]/span/span[1]')\n",
    "profile.click()\n",
    "\n",
    "UserTags = []\n",
    "TimeStamps = []\n",
    "Tweets = []\n",
    "\n",
    "# Fetch tweets\n",
    "while len(Tweets) < 30:\n",
    "    articles = driver.find_elements(By.XPATH, \"//article[@data-testid='tweet']\")\n",
    "    for article in articles:\n",
    "        UserTag = driver.find_element(By.XPATH, \".//div[@data-testid='UserName']\").text\n",
    "        UserTags.append(UserTag)\n",
    "\n",
    "        TimeStamp = driver.find_element(By.XPATH, \".//time\").get_attribute('datetime')\n",
    "        TimeStamps.append(TimeStamp)\n",
    "\n",
    "        Tweet = driver.find_element(By.XPATH, \".//div[@data-testid='tweetText']\").text\n",
    "        if Tweet not in Tweets:\n",
    "            Tweets.append(Tweet)\n",
    "\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    sleep(3)\n",
    "\n",
    "# Print lengths to verify\n",
    "print(len(UserTags), len(TimeStamps), len(Tweets))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(zip(UserTags, TimeStamps, Tweets), columns=['UserTags', 'TimeStamps', 'Tweets'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      UserTags                TimeStamps  \\\n",
      "0   The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
      "1   The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
      "2   The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
      "3   The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
      "4   The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
      "5   The Canadian Press Politics\\n@CdnPressPoli  2023-11-28T12:46:02.000Z   \n",
      "6   The Canadian Press Politics\\n@CdnPressPoli  2023-11-28T12:46:02.000Z   \n",
      "7   The Canadian Press Politics\\n@CdnPressPoli  2023-11-28T12:46:02.000Z   \n",
      "8   The Canadian Press Politics\\n@CdnPressPoli  2023-11-28T12:46:02.000Z   \n",
      "9   The Canadian Press Politics\\n@CdnPressPoli  2023-11-28T12:46:02.000Z   \n",
      "10  The Canadian Press Politics\\n@CdnPressPoli  2023-11-28T12:46:02.000Z   \n",
      "11  The Canadian Press Politics\\n@CdnPressPoli  2023-11-28T12:46:02.000Z   \n",
      "12  The Canadian Press Politics\\n@CdnPressPoli  2023-11-28T12:46:02.000Z   \n",
      "13  The Canadian Press Politics\\n@CdnPressPoli  2023-11-28T12:46:02.000Z   \n",
      "14  The Canadian Press Politics\\n@CdnPressPoli  2023-11-28T12:46:02.000Z   \n",
      "15  The Canadian Press Politics\\n@CdnPressPoli  2023-11-28T12:46:02.000Z   \n",
      "16  The Canadian Press Politics\\n@CdnPressPoli  2023-11-28T12:46:02.000Z   \n",
      "17  The Canadian Press Politics\\n@CdnPressPoli  2023-11-28T12:46:02.000Z   \n",
      "18  The Canadian Press Politics\\n@CdnPressPoli  2023-11-28T12:46:02.000Z   \n",
      "19  The Canadian Press Politics\\n@CdnPressPoli  2023-10-12T12:32:03.000Z   \n",
      "20  The Canadian Press Politics\\n@CdnPressPoli  2023-10-12T12:32:03.000Z   \n",
      "21  The Canadian Press Politics\\n@CdnPressPoli  2023-10-12T12:32:03.000Z   \n",
      "22  The Canadian Press Politics\\n@CdnPressPoli  2023-10-12T12:32:03.000Z   \n",
      "23  The Canadian Press Politics\\n@CdnPressPoli  2023-10-12T12:32:03.000Z   \n",
      "24  The Canadian Press Politics\\n@CdnPressPoli  2023-10-12T12:32:03.000Z   \n",
      "25  The Canadian Press Politics\\n@CdnPressPoli  2023-10-12T12:32:03.000Z   \n",
      "26  The Canadian Press Politics\\n@CdnPressPoli  2023-10-12T12:32:03.000Z   \n",
      "27  The Canadian Press Politics\\n@CdnPressPoli  2023-10-12T12:32:03.000Z   \n",
      "28  The Canadian Press Politics\\n@CdnPressPoli  2023-10-12T12:32:03.000Z   \n",
      "29  The Canadian Press Politics\\n@CdnPressPoli  2023-10-12T12:32:03.000Z   \n",
      "\n",
      "                                               Tweets  \n",
      "0   Canada's federal government was warned two yea...  \n",
      "1   MPs set to debate Ukraine trade deal, as Liber...  \n",
      "2   Ottawa locals to testify about 'Freedom Convoy...  \n",
      "3   India claims students at risk after envoy insi...  \n",
      "4   CSIS is leaning on Soviet imagery to help prim...  \n",
      "5   Biden's Inflation Reduction Act, one year on: ...  \n",
      "6   Sneakers of the House: Canada's MPs embrace co...  \n",
      "7   Centre Block on pace to reopen in 2032, includ...  \n",
      "8   Public Safety Minister Marco Mendicino's offic...  \n",
      "9   Canada sought use of European Union compound i...  \n",
      "10  Canada, South Korea agree to work together on ...  \n",
      "11  Defence minister says Canada wants to share ad...  \n",
      "12  Liberals table legislation to overhaul passeng...  \n",
      "13  'Slap in the face': Freeland's Disney Plus com...  \n",
      "14  Liberals pledge revamp of forced-labour bill, ...  \n",
      "15  Head of Canadian Museum of History looks to mo...  \n",
      "16  A look at what church, Indigenous and governme...  \n",
      "17  Military under fire as thousands of troops fac...  \n",
      "18  Canadian MPs of all stripes condemn Punjab cra...  \n",
      "19  My statement stands, Supreme Court justice say...  \n",
      "20  Ransomware attack hits engineering company wor...  \n",
      "21  Joni Mitchell honoured with Gershwin Prize at ...  \n",
      "22  China, Russia targeting Canada's artificial in...  \n",
      "23  Liberals appoint former broadcaster Tom Clark ...  \n",
      "24  Defence Minister Anita Anand says Canada is se...  \n",
      "25  Judge orders Ottawa to help repatriate four me...  \n",
      "26  Feds opt to focus on making access-to-info law...  \n",
      "27  Pierre Poilievre thinks he can win over new Ca...  \n",
      "28  Parliamentary study says government should exp...  \n",
      "29  Families Minister Karina Gould is expected to ...  \n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "df.to_csv('5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory containing CSV files\n",
    "directory = '/home/ishantk/Downloads/chromedriver-linux64 (3)'  # Replace with your directory path\n",
    "\n",
    "# Initialize an empty list to hold dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through all CSV files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes in the list\n",
    "merged_df = pd.concat(dfs)\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_df.to_csv('merged.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        UserTags                TimeStamps  \\\n",
      "0     The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
      "1     The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
      "2     The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
      "3     The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
      "4     The Canadian Press Politics\\n@CdnPressPoli  2024-01-11T14:46:47.000Z   \n",
      "...                                          ...                       ...   \n",
      "1015                  BBC Politics\\n@BBCPolitics  2024-06-28T18:39:30.000Z   \n",
      "1016                  BBC Politics\\n@BBCPolitics  2024-06-28T18:39:30.000Z   \n",
      "1017                  BBC Politics\\n@BBCPolitics  2024-06-28T18:39:30.000Z   \n",
      "1018                  BBC Politics\\n@BBCPolitics  2024-06-28T18:39:30.000Z   \n",
      "1019                  BBC Politics\\n@BBCPolitics  2024-06-28T08:01:25.000Z   \n",
      "\n",
      "                                                 Tweets  \n",
      "0     Canada's federal government was warned two yea...  \n",
      "1     MPs set to debate Ukraine trade deal, as Liber...  \n",
      "2     Ottawa locals to testify about 'Freedom Convoy...  \n",
      "3     India claims students at risk after envoy insi...  \n",
      "4     CSIS is leaning on Soviet imagery to help prim...  \n",
      "...                                                 ...  \n",
      "1015  Candidates for the 4 July general election hav...  \n",
      "1016  The Labour party has pledged to create 100,000...  \n",
      "1017  Tories insist Ross played no part in dropping ...  \n",
      "1018  \"Quite a few of the smaller party representati...  \n",
      "1019  Leading figures from seven parties face each o...  \n",
      "\n",
      "[1020 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('merged.csv')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m559.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:--:--\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.4.2 nltk-3.8.1 regex-2024.5.15 tqdm-4.66.4\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ishantk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ishantk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet preprocessing completed and dataset saved to 'cleaned_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize tools\n",
    "tokenizer = TweetTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    if isinstance(tweet, str):\n",
    "        # Convert to lowercase\n",
    "        tweet = tweet.lower()\n",
    "        \n",
    "        # Remove URLs\n",
    "        tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)\n",
    "        \n",
    "        # Remove mentions\n",
    "        tweet = re.sub(r'@\\w+', '', tweet)\n",
    "        \n",
    "        # Remove hashtags\n",
    "        tweet = re.sub(r'#\\w+', '', tweet)\n",
    "        \n",
    "        # Remove punctuation and special characters\n",
    "        tweet = re.sub(r'\\W', ' ', tweet)\n",
    "        \n",
    "        # Remove numbers\n",
    "        tweet = re.sub(r'\\d+', '', tweet)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = tokenizer.tokenize(tweet)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "        \n",
    "        # Join tokens back into a single string\n",
    "        tweet = ' '.join(tokens)\n",
    "    else:\n",
    "        tweet = ''\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('merged.csv')  # Replace with your dataset path\n",
    "\n",
    "# Apply preprocessing to each tweet\n",
    "df['cleaned_tweet'] = df['Tweets'].apply(preprocess_tweet)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_dataset.csv', index=False)  # Replace with your desired output file name\n",
    "\n",
    "print(\"Tweet preprocessing completed and dataset saved to 'cleaned_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis completed and dataset saved to 'sentiment_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('cleaned_dataset.csv')  # Replace 'your_dataset.csv' with your actual file path\n",
    "df = df.dropna(subset=['cleaned_tweet'])  # Replace 'tweet' with the specific column name\n",
    "\n",
    "# Load a pre-trained sentiment-analysis pipeline\n",
    "# sentiment_analysis = pipeline('sentiment-analysis')\n",
    "sentiment_analysis = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual\")\n",
    "# specific_model(data)\n",
    "\n",
    "\n",
    "# Function to get sentiment from the tweet\n",
    "def get_sentiment(text):\n",
    "    result = sentiment_analysis(text)[0]\n",
    "    return result['label'].lower()  # Convert the label to lowercase for consistency\n",
    "\n",
    "# Apply the sentiment analysis model to each tweet\n",
    "df['sentiment'] = df['cleaned_tweet'].apply(get_sentiment)\n",
    "\n",
    "# Save the new dataset with sentiment labels\n",
    "df.to_csv('sentiment_dataset6.csv', index=False)  # Replace with your desired output file name\n",
    "\n",
    "print(\"Sentiment analysis completed and dataset saved to 'sentiment_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m608.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from transformers)\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numpy<2.0,>=1.17 (from transformers)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/ishantk/.local/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ishantk/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n",
      "Downloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.1/142.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, pyyaml, numpy, fsspec, filelock, charset-normalizer, requests, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.0\n",
      "    Uninstalling numpy-2.0.0:\n",
      "      Successfully uninstalled numpy-2.0.0\n",
      "Successfully installed charset-normalizer-3.3.2 filelock-3.15.4 fsspec-2024.6.1 huggingface-hub-0.23.4 numpy-1.26.4 pyyaml-6.0.1 requests-2.32.3 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.42.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ishantk/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: fsspec in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.3.1 (from torch)\n",
      "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
      "Successfully installed MarkupSafe-2.1.5 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 sympy-1.12.1 torch-2.3.1 triton-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998656511306763},\n",
       " {'label': 'NEGATIVE', 'score': 0.9991129040718079}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install -q transformers\n",
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "data = [\"I love you\", \"I hate you\"]\n",
    "sentiment_pipeline(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis completed and dataset saved to 'sentiment_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('cleaned_dataset.csv')  # Replace with your dataset path\n",
    "# Remove rows with NaN entries in the 'tweet' column\n",
    "df = df.dropna(subset=['cleaned_tweet'])\n",
    "# Load a pre-trained sentiment-analysis pipeline based on distilbert\n",
    "sentiment_analysis = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "def get_sentiment(text):\n",
    "    if isinstance(text, str) and text.strip():  # Ensure text is a non-empty string\n",
    "        result = sentiment_analysis(text)[0]\n",
    "        return result['label'].lower()  # Convert the label to lowercase for consistency\n",
    "    else:\n",
    "        return 'neutral'  # You can choose to return 'neutral' or any default sentiment\n",
    "\n",
    "\n",
    "\n",
    "# Apply the sentiment analysis model to each tweet\n",
    "df['sentiment'] = df['cleaned_tweet'].apply(get_sentiment)\n",
    "\n",
    "# Save the new dataset with sentiment labels\n",
    "df.to_csv('sentiment_dataset5.csv', index=False)  # Replace with your desired output file name\n",
    "\n",
    "print(\"Sentiment analysis completed and dataset saved to 'sentiment_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from sentence-transformers) (4.42.3)\n",
      "Requirement already satisfied: tqdm in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: numpy in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m462.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.15.1 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from sentence-transformers) (0.23.4)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: filelock in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ishantk/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ishantk/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.5.82)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/ishantk/miniconda3/envs/myenv/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, Pillow, scikit-learn, sentence-transformers\n",
      "Successfully installed Pillow-10.4.0 scikit-learn-1.5.0 scipy-1.14.0 sentence-transformers-3.0.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
